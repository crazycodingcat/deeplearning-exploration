{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Theanets to Implement Word/Image Vector fusion\n",
    "- [source of both idea and code](https://github.com/mganjoo/zslearning)\n",
    "- [a theano based implementation] - http://nbviewer.ipython.org/github/renruoxu/data-fusion/blob/master/deprecated/mapping%20(1).ipynb\n",
    "- it is a standard 1-hidden layer MLP with customized cost function\n",
    "- the data we use here is that: X (image vectors from DeCaff), Y (word vectors from word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import theanets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, pairwise_distances_argmin, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LABELS = np.array([\"airplane\", \"automobile\", \"bird\",\"cat\",\n",
    "                        \"deer\",\"dog\",\"frog\", \"horse\", \"ship\",\"truck\"])\n",
    "word2vec = Word2Vec.load_word2vec_format(\"../data/word2vec.bin\", binary = True)\n",
    "label_vecs = np.vstack([word2vec[w] for w in LABELS],)\n",
    "\n",
    "store = pd.HDFStore(\"../data/cifa_XY.hd5\")\n",
    "X = store[\"X/\"].get_values()\n",
    "y = store[\"Y/\"].get_values()\n",
    "labels = pairwise_distances_argmin(y, label_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## we train a mapping model with data excluding trucks\n",
    "## and later test whether the truck images are correctly mapped to word truck\n",
    "\n",
    "truck_index = (labels == 9) ## 5 is dog in LABELS, 9 is truck\n",
    "X_notruck, y_notruck = X[~truck_index], y[~truck_index]\n",
    "X_truck, y_truck= X[truck_index], y[truck_index]\n",
    "label_notruck, label_truck = labels[~truck_index], labels[truck_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss(err) 1.68573136264 (0.597772) valid loss(err) 3.76488697797 (2.41783)\n",
      "train loss(err) 1.34929347464 (0.437853) valid loss(err) 3.76488697797 (2.41783)\n",
      "train loss(err) 1.20145874518 (0.399815) valid loss(err) 3.76488697797 (2.41783)\n",
      "train loss(err) 1.09891567713 (0.377175) valid loss(err) 3.76488697797 (2.41783)\n",
      "train loss(err) 1.01905407773 (0.360199) valid loss(err) 3.76488697797 (2.41783)\n",
      "train loss(err) 0.955991123965 (0.348181) valid loss(err) 0.999821141798 (0.366643)\n",
      "train loss(err) 0.902614026235 (0.337333) valid loss(err) 0.999821141798 (0.366643)\n",
      "train loss(err) 0.857097751347 (0.328115) valid loss(err) 0.999821141798 (0.366643)\n",
      "train loss(err) 0.820832327485 (0.321286) valid loss(err) 0.999821141798 (0.366643)\n",
      "train loss(err) 0.788851433504 (0.314502) valid loss(err) 0.999821141798 (0.366643)\n",
      "train loss(err) 0.75943461884 (0.308164) valid loss(err) 0.799218676212 (0.336216)\n",
      "train loss(err) 0.736125404855 (0.303747) valid loss(err) 0.799218676212 (0.336216)\n",
      "train loss(err) 0.714530964063 (0.299358) valid loss(err) 0.799218676212 (0.336216)\n",
      "train loss(err) 0.695155502628 (0.295266) valid loss(err) 0.799218676212 (0.336216)\n",
      "train loss(err) 0.678757805952 (0.291145) valid loss(err) 0.799218676212 (0.336216)\n",
      "train loss(err) 0.664331218066 (0.287461) valid loss(err) 0.702770432985 (0.321256)\n",
      "train loss(err) 0.652310584761 (0.285304) valid loss(err) 0.702770432985 (0.321256)\n",
      "train loss(err) 0.637330567464 (0.280956) valid loss(err) 0.702770432985 (0.321256)\n",
      "train loss(err) 0.625703288008 (0.27789) valid loss(err) 0.702770432985 (0.321256)\n",
      "train loss(err) 0.613964791245 (0.275161) valid loss(err) 0.702770432985 (0.321256)\n",
      "train loss(err) 0.605434626471 (0.273439) valid loss(err) 0.647414804676 (0.309861)\n",
      "train loss(err) 0.594252641632 (0.269767) valid loss(err) 0.647414804676 (0.309861)\n",
      "train loss(err) 0.585015531772 (0.267454) valid loss(err) 0.647414804676 (0.309861)\n",
      "train loss(err) 0.578337699436 (0.265585) valid loss(err) 0.647414804676 (0.309861)\n",
      "train loss(err) 0.570666086107 (0.264158) valid loss(err) 0.647414804676 (0.309861)\n",
      "train loss(err) 0.564384754392 (0.261631) valid loss(err) 0.604532309116 (0.301242)\n",
      "train loss(err) 0.559006423307 (0.26004) valid loss(err) 0.604532309116 (0.301242)\n",
      "train loss(err) 0.55519985097 (0.258162) valid loss(err) 0.604532309116 (0.301242)\n",
      "train loss(err) 0.548716640804 (0.255443) valid loss(err) 0.604532309116 (0.301242)\n",
      "train loss(err) 0.544503214904 (0.253961) valid loss(err) 0.604532309116 (0.301242)\n",
      "train loss(err) 0.540629110026 (0.252795) valid loss(err) 0.58905667797 (0.301968)\n",
      "train loss(err) 0.535537601563 (0.25036) valid loss(err) 0.58905667797 (0.301968)\n",
      "train loss(err) 0.533249294446 (0.250345) valid loss(err) 0.58905667797 (0.301968)\n",
      "train loss(err) 0.529463419778 (0.24866) valid loss(err) 0.58905667797 (0.301968)\n",
      "train loss(err) 0.526109457324 (0.247638) valid loss(err) 0.58905667797 (0.301968)\n",
      "train loss(err) 0.52187703813 (0.245849) valid loss(err) 0.571387280828 (0.296329)\n",
      "train loss(err) 0.518387818366 (0.24417) valid loss(err) 0.571387280828 (0.296329)\n",
      "train loss(err) 0.515848821927 (0.243426) valid loss(err) 0.571387280828 (0.296329)\n",
      "train loss(err) 0.512849406189 (0.24238) valid loss(err) 0.571387280828 (0.296329)\n",
      "train loss(err) 0.50872480806 (0.240372) valid loss(err) 0.571387280828 (0.296329)\n",
      "train loss(err) 0.507377850575 (0.239913) valid loss(err) 0.563774456603 (0.295195)\n",
      "train loss(err) 0.504136811469 (0.23872) valid loss(err) 0.563774456603 (0.295195)\n",
      "train loss(err) 0.501189101582 (0.237908) valid loss(err) 0.563774456603 (0.295195)\n",
      "train loss(err) 0.497950011155 (0.236537) valid loss(err) 0.563774456603 (0.295195)\n",
      "train loss(err) 0.496262565519 (0.235825) valid loss(err) 0.563774456603 (0.295195)\n",
      "train loss(err) 0.494050804526 (0.234864) valid loss(err) 0.556073658323 (0.29961)\n",
      "train loss(err) 0.491785899473 (0.234068) valid loss(err) 0.556073658323 (0.29961)\n",
      "train loss(err) 0.48964093861 (0.233251) valid loss(err) 0.556073658323 (0.29961)\n",
      "train loss(err) 0.48857137309 (0.232659) valid loss(err) 0.556073658323 (0.29961)\n",
      "train loss(err) 0.486527388563 (0.231592) valid loss(err) 0.556073658323 (0.29961)\n",
      "train loss(err) 0.484715738871 (0.231374) valid loss(err) 0.552760185187 (0.299059)\n",
      "train loss(err) 0.48353187789 (0.230391) valid loss(err) 0.552760185187 (0.299059)\n",
      "train loss(err) 0.4819204954 (0.229603) valid loss(err) 0.552760185187 (0.299059)\n",
      "train loss(err) 0.479500229184 (0.228576) valid loss(err) 0.552760185187 (0.299059)\n",
      "train loss(err) 0.478678901866 (0.228536) valid loss(err) 0.552760185187 (0.299059)\n",
      "train loss(err) 0.476559805052 (0.227547) valid loss(err) 0.541926987569 (0.29345)\n",
      "train loss(err) 0.474644317535 (0.226657) valid loss(err) 0.541926987569 (0.29345)\n",
      "train loss(err) 0.473691519543 (0.226592) valid loss(err) 0.541926987569 (0.29345)\n",
      "train loss(err) 0.472586752716 (0.226288) valid loss(err) 0.541926987569 (0.29345)\n",
      "train loss(err) 0.471022375164 (0.225438) valid loss(err) 0.541926987569 (0.29345)\n",
      "train loss(err) 0.467833670035 (0.223922) valid loss(err) 0.53317765642 (0.290035)\n",
      "train loss(err) 0.466268417939 (0.223028) valid loss(err) 0.53317765642 (0.290035)\n",
      "train loss(err) 0.465754228099 (0.223522) valid loss(err) 0.53317765642 (0.290035)\n",
      "train loss(err) 0.464210904227 (0.222756) valid loss(err) 0.53317765642 (0.290035)\n",
      "train loss(err) 0.462124808159 (0.22159) valid loss(err) 0.53317765642 (0.290035)\n",
      "train loss(err) 0.46197399757 (0.222036) valid loss(err) 0.533295391416 (0.294246)\n",
      "train loss(err) 0.460160727212 (0.221209) valid loss(err) 0.533295391416 (0.294246)\n",
      "train loss(err) 0.458746837971 (0.221098) valid loss(err) 0.533295391416 (0.294246)\n",
      "train loss(err) 0.456924190556 (0.219938) valid loss(err) 0.533295391416 (0.294246)\n",
      "train loss(err) 0.456748326124 (0.220186) valid loss(err) 0.533295391416 (0.294246)\n",
      "train loss(err) 0.454631854732 (0.219079) valid loss(err) 0.526767669266 (0.290441)\n",
      "train loss(err) 0.453590148321 (0.218818) valid loss(err) 0.526767669266 (0.290441)\n",
      "train loss(err) 0.45197785464 (0.21828) valid loss(err) 0.526767669266 (0.290441)\n",
      "train loss(err) 0.451097313308 (0.218008) valid loss(err) 0.526767669266 (0.290441)\n",
      "train loss(err) 0.451012807163 (0.217774) valid loss(err) 0.526767669266 (0.290441)\n",
      "train loss(err) 0.449457540086 (0.217241) valid loss(err) 0.525098412304 (0.29041)\n",
      "train loss(err) 0.448467029811 (0.216517) valid loss(err) 0.525098412304 (0.29041)\n",
      "train loss(err) 0.447294841186 (0.216123) valid loss(err) 0.525098412304 (0.29041)\n",
      "train loss(err) 0.446529467392 (0.215588) valid loss(err) 0.525098412304 (0.29041)\n",
      "train loss(err) 0.445282531319 (0.214912) valid loss(err) 0.525098412304 (0.29041)\n",
      "train loss(err) 0.444223038999 (0.21428) valid loss(err) 0.520226797065 (0.288425)\n",
      "train loss(err) 0.442369594278 (0.213064) valid loss(err) 0.520226797065 (0.288425)\n",
      "train loss(err) 0.442804732597 (0.213697) valid loss(err) 0.520226797065 (0.288425)\n",
      "train loss(err) 0.442099486194 (0.213297) valid loss(err) 0.520226797065 (0.288425)\n",
      "train loss(err) 0.44066333596 (0.212168) valid loss(err) 0.520226797065 (0.288425)\n",
      "train loss(err) 0.440705753657 (0.212588) valid loss(err) 0.517550286387 (0.292354)\n",
      "train loss(err) 0.439295882345 (0.211832) valid loss(err) 0.517550286387 (0.292354)\n",
      "train loss(err) 0.440175679479 (0.212618) valid loss(err) 0.517550286387 (0.292354)\n",
      "train loss(err) 0.438348671259 (0.211293) valid loss(err) 0.517550286387 (0.292354)\n",
      "train loss(err) 0.438140845814 (0.211366) valid loss(err) 0.517550286387 (0.292354)\n",
      "train loss(err) 0.436482508546 (0.210393) valid loss(err) 0.522578304857 (0.294154)\n",
      "train loss(err) 0.435377685091 (0.210146) valid loss(err) 0.522578304857 (0.294154)\n",
      "train loss(err) 0.434916051705 (0.210038) valid loss(err) 0.522578304857 (0.294154)\n",
      "train loss(err) 0.434986332901 (0.209968) valid loss(err) 0.522578304857 (0.294154)\n",
      "train loss(err) 0.433131900876 (0.208858) valid loss(err) 0.522578304857 (0.294154)\n",
      "train loss(err) 0.432213368945 (0.208478) valid loss(err) 0.515147692554 (0.290199)\n",
      "train loss(err) 0.432787948177 (0.208863) valid loss(err) 0.515147692554 (0.290199)\n",
      "train loss(err) 0.431938140102 (0.208768) valid loss(err) 0.515147692554 (0.290199)\n",
      "train loss(err) 0.431067024724 (0.207993) valid loss(err) 0.515147692554 (0.290199)\n",
      "train loss(err) 0.431054730275 (0.208026) valid loss(err) 0.515147692554 (0.290199)\n",
      "train loss(err) 0.429847844859 (0.207385) valid loss(err) 0.511893777986 (0.289908)\n",
      "train loss(err) 0.428913797969 (0.207007) valid loss(err) 0.511893777986 (0.289908)\n",
      "train loss(err) 0.428767724823 (0.206833) valid loss(err) 0.511893777986 (0.289908)\n",
      "train loss(err) 0.428903379197 (0.207045) valid loss(err) 0.511893777986 (0.289908)\n",
      "train loss(err) 0.428323318208 (0.206322) valid loss(err) 0.511893777986 (0.289908)\n",
      "train loss(err) 0.427218151873 (0.2058) valid loss(err) 0.518410665037 (0.294917)\n",
      "train loss(err) 0.426680651013 (0.205431) valid loss(err) 0.518410665037 (0.294917)\n",
      "train loss(err) 0.425254897901 (0.204507) valid loss(err) 0.518410665037 (0.294917)\n",
      "train loss(err) 0.424846746879 (0.204151) valid loss(err) 0.518410665037 (0.294917)\n",
      "train loss(err) 0.423366782413 (0.203084) valid loss(err) 0.518410665037 (0.294917)\n",
      "train loss(err) 0.42439242387 (0.204259) valid loss(err) 0.50954940262 (0.288661)\n",
      "train loss(err) 0.424240166149 (0.203922) valid loss(err) 0.50954940262 (0.288661)\n",
      "train loss(err) 0.424296829799 (0.204242) valid loss(err) 0.50954940262 (0.288661)\n",
      "train loss(err) 0.423548562303 (0.203296) valid loss(err) 0.50954940262 (0.288661)\n",
      "train loss(err) 0.423117185198 (0.203235) valid loss(err) 0.50954940262 (0.288661)\n",
      "train loss(err) 0.422459898171 (0.202957) valid loss(err) 0.513533260756 (0.294481)\n",
      "train loss(err) 0.42230828386 (0.202895) valid loss(err) 0.513533260756 (0.294481)\n",
      "train loss(err) 0.42059651103 (0.201666) valid loss(err) 0.513533260756 (0.294481)\n",
      "train loss(err) 0.420437078172 (0.201366) valid loss(err) 0.513533260756 (0.294481)\n",
      "train loss(err) 0.420337671796 (0.201639) valid loss(err) 0.513533260756 (0.294481)\n",
      "train loss(err) 0.420068070666 (0.201224) valid loss(err) 0.503128850147 (0.28604)\n",
      "train loss(err) 0.419725570598 (0.201193) valid loss(err) 0.503128850147 (0.28604)\n",
      "train loss(err) 0.418852727371 (0.200412) valid loss(err) 0.503128850147 (0.28604)\n",
      "train loss(err) 0.419391727256 (0.200948) valid loss(err) 0.503128850147 (0.28604)\n",
      "train loss(err) 0.418964785124 (0.200474) valid loss(err) 0.503128850147 (0.28604)\n",
      "train loss(err) 0.418554825128 (0.200391) valid loss(err) 0.509285784948 (0.287461)\n",
      "train loss(err) 0.41747431475 (0.199421) valid loss(err) 0.509285784948 (0.287461)\n",
      "train loss(err) 0.417698975271 (0.199685) valid loss(err) 0.509285784948 (0.287461)\n",
      "train loss(err) 0.417507469121 (0.199463) valid loss(err) 0.509285784948 (0.287461)\n",
      "train loss(err) 0.418058607046 (0.200331) valid loss(err) 0.509285784948 (0.287461)\n",
      "train loss(err) 0.417070024461 (0.199487) valid loss(err) 0.503667402869 (0.284959)\n",
      "train loss(err) 0.416565820547 (0.199102) valid loss(err) 0.503667402869 (0.284959)\n",
      "train loss(err) 0.416688254566 (0.19898) valid loss(err) 0.503667402869 (0.284959)\n",
      "train loss(err) 0.416361702714 (0.199049) valid loss(err) 0.503667402869 (0.284959)\n",
      "train loss(err) 0.415924027163 (0.198984) valid loss(err) 0.503667402869 (0.284959)\n",
      "train loss(err) 0.415357220745 (0.198886) valid loss(err) 0.510791738219 (0.293254)\n",
      "train loss(err) 0.415845491931 (0.199216) valid loss(err) 0.510791738219 (0.293254)\n",
      "train loss(err) 0.414387896557 (0.198265) valid loss(err) 0.510791738219 (0.293254)\n",
      "train loss(err) 0.415549944594 (0.199145) valid loss(err) 0.510791738219 (0.293254)\n",
      "train loss(err) 0.413953502044 (0.197786) valid loss(err) 0.510791738219 (0.293254)\n",
      "train loss(err) 0.413510959327 (0.197675) valid loss(err) 0.503562866076 (0.289434)\n",
      "train loss(err) 0.414330685401 (0.198365) valid loss(err) 0.503562866076 (0.289434)\n",
      "train loss(err) 0.41305699277 (0.197335) valid loss(err) 0.503562866076 (0.289434)\n",
      "train loss(err) 0.413378237802 (0.197928) valid loss(err) 0.503562866076 (0.289434)\n",
      "train loss(err) 0.411906566319 (0.196916) valid loss(err) 0.503562866076 (0.289434)\n",
      "CPU times: user 8h 11min 32s, sys: 9h 46s, total: 17h 12min 18s\n",
      "Wall time: 33min 21s\n"
     ]
    }
   ],
   "source": [
    "def train_model(X, y):\n",
    "    \n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size = 10000)\n",
    "    \n",
    "    ss_X = StandardScaler().fit(train_X)\n",
    "    ss_y = StandardScaler().fit(train_y)\n",
    "    scaled_train_X, scaled_valid_X = ss_X.transform(train_X), ss_X.transform(valid_X)\n",
    "    scaled_train_y, scaled_valid_y = ss_y.transform(train_y), ss_y.transform(valid_y)\n",
    "    \n",
    "    exp = theanets.Experiment(theanets.Regressor, layers = (4096, (200, \"tanh\"), 100))\n",
    "    for train, valid in exp.itertrain(train_set = (scaled_train_X, scaled_train_y), \n",
    "                                  valid_set = (scaled_valid_X, scaled_valid_y), \n",
    "                                  optimize = \"sgd\", learning_rate = 0.005, \n",
    "                                  validate_every = 5, batch_size = 32,\n",
    "                                  hidden_l1 = 0.01, weight_l2 = 1e-4):\n",
    "        print 'train loss(err)', train['loss'], \"(%g)\" % train[\"err\"], 'valid loss(err)', valid['loss'], \"(%g)\" % valid['err']\n",
    "    return ss_X, ss_y, exp.network\n",
    "\n",
    "%time ss_X, ss_y, model = train_model(X_notruck, y_notruck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_by_model(xscaler, yscaler, model, X):\n",
    "    yhat = yscaler.inverse_transform(model.predict(xscaler.transform(X)))\n",
    "    return pairwise_distances_argmin(yhat, label_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>airplane</th>\n",
       "      <td>5451</td>\n",
       "      <td>38</td>\n",
       "      <td>123</td>\n",
       "      <td>42</td>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>62</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automobile</th>\n",
       "      <td>77</td>\n",
       "      <td>5750</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>146</td>\n",
       "      <td>10</td>\n",
       "      <td>4999</td>\n",
       "      <td>259</td>\n",
       "      <td>201</td>\n",
       "      <td>126</td>\n",
       "      <td>184</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>52</td>\n",
       "      <td>13</td>\n",
       "      <td>289</td>\n",
       "      <td>4441</td>\n",
       "      <td>169</td>\n",
       "      <td>654</td>\n",
       "      <td>220</td>\n",
       "      <td>135</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deer</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "      <td>193</td>\n",
       "      <td>4968</td>\n",
       "      <td>74</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>212</td>\n",
       "      <td>616</td>\n",
       "      <td>122</td>\n",
       "      <td>4812</td>\n",
       "      <td>79</td>\n",
       "      <td>140</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frog</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "      <td>211</td>\n",
       "      <td>87</td>\n",
       "      <td>62</td>\n",
       "      <td>5407</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horse</th>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>113</td>\n",
       "      <td>201</td>\n",
       "      <td>141</td>\n",
       "      <td>225</td>\n",
       "      <td>26</td>\n",
       "      <td>5238</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ship</th>\n",
       "      <td>203</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>5670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            airplane  automobile  bird   cat  deer   dog  frog  horse  ship\n",
       "airplane        5451          38   123    42    46    16    21     62   201\n",
       "automobile        77        5750    19    29     9     8    10     31    67\n",
       "bird             146          10  4999   259   201   126   184     52    23\n",
       "cat               52          13   289  4441   169   654   220    135    27\n",
       "deer              49           1   326   193  4968    74   187    189    13\n",
       "dog                6           4   212   616   122  4812    79    140     9\n",
       "frog              23           3   179   211    87    62  5407     19     9\n",
       "horse             26          11   113   201   141   225    26   5238    19\n",
       "ship             203          45    19    27     3    15     6     12  5670"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for images already seen\n",
    "yhat_notruck = predict_by_model(ss_X, ss_y, model, X_notruck)\n",
    "NOTRUCK_LABELS = [l for l in LABELS if l != \"truck\"]\n",
    "cm = pd.DataFrame(confusion_matrix(label_notruck, yhat_notruck), \n",
    "                  index = NOTRUCK_LABELS, columns=NOTRUCK_LABELS)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'automobile': 3856, 'airplane': 909, 'ship': 518, 'horse': 372, 'cat': 159, 'bird': 64, 'dog': 55, 'deer': 37, 'frog': 30})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for unseen (truck) images - how are they map to the text\n",
    "yhat_truck = predict_by_model(ss_X, ss_y, model, X_truck)\n",
    "Counter(LABELS[yhat_truck])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** we see that even we don't see truck images before, most of them will be mapped to the word \"automobile\". But unfortunatelly none of the new images are really mapped to the word \"truck\" - obviously the mapping does a better job for interpolation than for extrapolation. For example, the arithmetic relation between the words \"truck\" and \"automobile\" are NOT captured by the mapping from images to words - because the image vectors themselves don't have similiar arithmetic relations as in word2vec. This could be caused by the lack of enough words for images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
